# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Algorithmic trading platform built on **Backtrader** (open-source) with Interactive Brokers integration. This is a Python-based backtesting and live trading system using Docker for containerized deployment.

**Migration Status**: ‚úÖ Successfully migrated from LEAN to Backtrader (Nov 2025)
**Architecture**: Backtrader-Native - All trading logic runs inside Backtrader strategies with IB integration via ib_insync.

**See**: [MIGRATION_SUMMARY.md](MIGRATION_SUMMARY.md) for complete migration details.

## Environment Management

**CRITICAL**: This project uses a Python virtual environment. ALWAYS activate it before running Python commands:

```bash
source venv/bin/activate.fish
```

All Python commands (pip, python scripts) MUST run within the virtual environment.

## Docker Architecture

The platform uses a 4-service Docker architecture orchestrated via [docker-compose.yml](docker-compose.yml):

1. **backtrader**: Backtrader trading engine (Python 3.12 + Backtrader 1.9.78.123)
2. **ib-gateway**: Interactive Brokers Gateway (headless) - handles broker connectivity
3. **sqlite**: Trade history database
4. **monitoring**: Streamlit dashboard on port 8501

All services communicate via `trading-network` bridge network.

### Service Startup/Shutdown

```bash
# Start all services (preferred method)
./scripts/start.sh

# Stop all services
./scripts/stop.sh

# View logs (NEVER use -f flag as per project rules)
docker compose logs backtrader
docker compose logs ib-gateway

# Restart specific service
docker compose restart backtrader
```

## Interactive Brokers Integration

### Credentials Setup

IB credentials are managed through `.env` file and Docker secrets:
- Username/password stored in `.env` (gitignored)
- Password also mounted as Docker secret at `/run/secrets/ib_password`
- Trading mode: `paper` (default) or `live`

### Connection Architecture

[scripts/ib_connection.py](scripts/ib_connection.py) provides `IBConnectionManager` class with:
- **ib_insync-based** connection manager (fully implemented)
- Exponential backoff retry (3 attempts: 1s, 2s, 4s)
- Health checks every 30 seconds
- Context manager support for automatic connection lifecycle
- Port 4001 for paper trading, 4002 for live (default: 4001)

## Backtrader Commands

All Backtrader operations run via Python scripts inside or outside Docker:

```bash
# Test IB connection
docker exec backtrader-engine python /app/scripts/ib_connection.py

# Download historical data (request from developer)
# Request: "Please download historical data for SPY, AAPL from 2024-01-01 to 2024-12-31 in Daily resolution"

# Run backtest via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" \
  -H "Content-Type: application/json" \
  -d '{
    "strategy": "sma_crossover",
    "symbols": ["SPY"],
    "parameters": {"fast_period": 10, "slow_period": 20},
    "start_date": "2024-01-01",
    "end_date": "2024-12-31"
  }'
```

## QuantConnect Cloud Backtesting

**Status**: ‚úÖ Integrated - LEAN projects with cloud automation

**Project Structure**:
```
lean_projects/
‚îú‚îÄ‚îÄ RSIMeanReversion/     # LEAN strategy project
‚îÇ   ‚îî‚îÄ‚îÄ main.py          # Strategy code
‚îú‚îÄ‚îÄ data/                # Sample data
‚îî‚îÄ‚îÄ lean.json            # LEAN configuration
```

### Run Cloud Backtest

**Via Automation Script** (Recommended):
```bash
source venv/bin/activate

# Quick backtest (open browser)
python scripts/qc_cloud_backtest.py --open

# Full workflow (commit, push, wait, save results)
python scripts/qc_cloud_backtest.py --commit --wait --save --open

# Without push (test existing code)
python scripts/qc_cloud_backtest.py --no-push --open
```

**Via LEAN CLI Directly**:
```bash
cd lean_projects

# Push to cloud
lean cloud push --project RSIMeanReversion

# Run backtest
lean cloud backtest RSIMeanReversion --open

# Download results
lean cloud results <backtest-id>
```

**Script Options**:
- `--commit` - Commit and push to GitHub first
- `--open` - Open results in browser
- `--wait` - Wait for backtest to complete
- `--save` - Download and save results locally
- `--no-push` - Skip pushing to QC cloud

**Output**: Results in terminal + URL to https://www.quantconnect.com/project/...

### MLflow Experiment Tracking (Epic 17)

**Status**: ‚úÖ Implemented - AI-Native Research Lab with centralized experiment tracking.

#### Enable MLflow Logging

```bash
# Submit backtest with MLflow tracking via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" \
  -H "Content-Type: application/json" \
  -d '{
    "strategy": "sma_crossover",
    "symbols": ["SPY"],
    "parameters": {"fast_period": 10, "slow_period": 20},
    "start_date": "2020-01-01",
    "end_date": "2024-12-31",
    "mlflow_project": "Q1_2025",
    "mlflow_asset_class": "Equities",
    "mlflow_strategy_family": "MeanReversion"
  }'

# High-frequency backtest via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" \
  -H "Content-Type: application/json" \
  -d '{
    "strategy": "sma_crossover",
    "symbols": ["SPY"],
    "parameters": {"fast_period": 10, "slow_period": 20},
    "start_date": "2025-10-07",
    "end_date": "2025-10-14",
    "resolution": "1m",
    "mlflow_project": "HighFreq_2025",
    "mlflow_asset_class": "Equities",
    "mlflow_strategy_family": "MeanReversion"
  }'
```

#### MLflow Features

- **Centralized Tracking**: All backtests logged to PostgreSQL-backed MLflow server
- **Project Hierarchy**: Dot notation organization (Project.AssetClass.StrategyFamily.Strategy)
- **Advanced Metrics**: 30+ metrics including Sortino, Calmar, regime analysis, alpha/beta
- **Artifact Storage**: Equity curves, trade logs, strategy plots, tearsheets
- **Experiment Comparison**: Compare strategies across projects and time periods

#### Access MLflow UI

```bash
# Start services (includes MLflow on port 5000)
./scripts/start.sh

# Open MLflow UI
open http://localhost:5000
```

#### Experiment Organization

**Naming Convention**: `{Project}.{AssetClass}.{StrategyFamily}.{Strategy}`
- `Q1_2025.Equities.MeanReversion.SMACrossover`
- `Q2_2025.Crypto.Momentum.RSIStrategy`

**Tags**: Comprehensive tagging for filtering and organization
- Project, Asset Class, Strategy Family, Team, Status
- Symbols, Time Period, Benchmark

#### Advanced Metrics (Epic 17)

Backtests now include:
- **QuantStats**: 30+ advanced metrics (Sortino, Calmar, Omega, VaR, CVaR)
- **Regime Analysis**: Bull/bear market performance breakdown
- **Alpha/Beta**: Benchmark comparison vs SPY
- **HTML Tearsheets**: Comprehensive performance reports

#### Bayesian Parameter Optimization (Epic 17)

**Status**: ‚úÖ Implemented - Optuna-based intelligent optimization with MLflow integration.

```bash
# Single optimization job via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/optimization/run" \
  -H "Content-Type: application/json" \
  -d '{
    "strategy": "sma_crossover",
    "symbols": ["SPY"],
    "parameter_space": {
      "fast_period": {"type": "int", "low": 5, "high": 20},
      "slow_period": {"type": "int", "low": 15, "high": 50}
    },
    "start_date": "2020-01-01",
    "end_date": "2024-12-31",
    "metric": "sharpe_ratio",
    "n_trials": 100,
    "study_name": "sma_opt_v1"
  }'

# High-frequency optimization via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/optimization/run" \
  -H "Content-Type: application/json" \
  -d '{
    "strategy": "sma_crossover",
    "symbols": ["SPY"],
    "parameter_space": {
      "fast_period": {"type": "int", "low": 5, "high": 20},
      "slow_period": {"type": "int", "low": 15, "high": 50}
    },
    "start_date": "2025-10-07",
    "end_date": "2025-10-14",
    "resolution": "1m",
    "metric": "sharpe_ratio",
    "n_trials": 50,
    "study_name": "hf_sma_opt_v1"
  }'

# Multi-symbol optimization via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/optimization/run" \
  -H "Content-Type: application/json" \
  -d '{
    "strategy": "rsi_momentum",
    "symbols": ["SPY", "AAPL", "MSFT"],
    "parameter_space": {
      "rsi_period": {"type": "int", "low": 10, "high": 30},
      "overbought_level": {"type": "int", "low": 65, "high": 80},
      "oversold_level": {"type": "int", "low": 20, "high": 35}
    },
    "start_date": "2021-01-01",
    "end_date": "2024-12-31",
    "metric": "sortino_ratio",
    "n_trials": 50,
    "study_name": "multi_symbol_rsi_opt"
  }'
```

**Features**:
- **Bayesian Optimization**: Optuna TPE sampler for intelligent parameter search
- **Parallel Execution**: Multi-threaded optimization trials within single container
- **Multi-Symbol Support**: Optimize across multiple symbols (sequential processing)
- **MLflow Integration**: Parent-child run structure for study tracking
- **Parameter Constraints**: Strategy-aware validation (SMA fast < slow)
- **Study Resumption**: Continue interrupted optimization studies
- **Early Stopping**: Median pruner for efficient convergence

**Note**: For distributed optimization across multiple machines/containers, combine with parallel backtesting for individual trials.

#### Parallel Backtesting (Epic 20)

**Status**: ‚úÖ Implemented - Redis-based distributed parallel backtesting with unlimited horizontal scaling.

```bash
# Submit multiple backtest jobs via API (parallel execution)
SYMBOLS=("SPY" "AAPL" "MSFT" "GOOGL" "AMZN")
STRATEGY="sma_crossover"

for symbol in "${SYMBOLS[@]}"; do
  curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" \
    -H "Content-Type: application/json" \
    -d "{\"strategy\": \"$STRATEGY\", \"symbols\": [\"$symbol\"], \"parameters\": {\"fast_period\": 10, \"slow_period\": 30}}" &
done

# High-frequency parallel backtests via API
HIGH_FREQ_SYMBOLS=("SPY" "QQQ" "NVDA" "TSLA")
for symbol in "${HIGH_FREQ_SYMBOLS[@]}"; do
  curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" \
    -H "Content-Type: application/json" \
    -d "{\"strategy\": \"sma_crossover\", \"symbols\": [\"$symbol\"], \"parameters\": {\"fast_period\": 5, \"slow_period\": 15}, \"start_date\": \"2025-10-07\", \"end_date\": \"2025-10-14\", \"resolution\": \"1m\"}" &
done

# Multiple strategies per symbol via API
STRATEGIES=("sma_crossover" "rsi_momentum")
for strategy in "${STRATEGIES[@]}"; do
  curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" \
    -H "Content-Type: application/json" \
    -d "{\"strategy\": \"$strategy\", \"symbols\": [\"SPY\"], \"parameters\": {\"fast_period\": 10, \"slow_period\": 30}}" &
done

# Monitor job status via API
curl "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests" | jq '.[] | {id: .id, status: .status, strategy: .strategy}'
```

**Features**:
- **Redis Queue**: Job queuing with unlimited horizontal scaling
- **Docker Workers**: 3+ containerized workers for distributed execution
- **MLflow Integration**: Automatic experiment tracking for all parallel runs
- **Batch Processing**: Execute 100+ backtests simultaneously
- **Results Consolidation**: Unified DataFrame output with performance metrics
- **Health Monitoring**: Worker health checks and automatic recovery

**Architecture**:
- **Redis Queue**: Job distribution and result aggregation
- **Worker Containers**: Isolated execution environments
- **Results Consolidator**: Unified metrics and performance analysis
- **MLflow Logger**: Experiment tracking and comparison

#### Symbol Discovery & Strategy Ranking API (Epic 26)

**Status**: ‚úÖ Implemented - API-first approach for autonomous Quant Director operations with background processing.

**Symbol Discovery API**:
```bash
# Submit discovery scan via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/discovery/scan" \
  -H "Content-Type: application/json" \
  -d '{
    "scanner_name": "high_volume",
    "parameters": {"number_of_rows": 50},
    "filters": {"liquidity": {"min_avg_volume": 2000000}}
  }'

# Check discovery job status
curl "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/discovery/status/{job_id}"

# Get discovery results
curl "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/discovery/results/{job_id}"
```

**Strategy Ranking API**:
```bash
# Submit ranking analysis via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/ranking/analyze" \
  -H "Content-Type: application/json" \
  -d '{
    "input_type": "results_dir",
    "input_source": "results/backtests",
    "criteria_weights": {
      "sharpe_ratio": 40.0,
      "consistency": 20.0,
      "drawdown_control": 20.0,
      "trade_frequency": 10.0,
      "capital_efficiency": 10.0
    }
  }'

# Check ranking job status
curl "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/ranking/status/{job_id}"

# Get ranking results
curl "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/ranking/results/{job_id}"
```

**Features**:
- **Background Processing**: Redis queue with dedicated discovery and ranking workers
- **Job Status Tracking**: Real-time monitoring of all background jobs
- **Database Persistence**: PostgreSQL storage for discovery results and ranking data
- **API Documentation**: Complete OpenAPI specs at http://localhost:8230/docs
- **Docker Integration**: Containerized workers (discovery-worker, ranking-worker)

#### Strategy Ranking & Portfolio Optimization (Epic 21)

**Status**: ‚úÖ Implemented - Systematic strategy evaluation and portfolio construction with multi-criteria ranking.

```bash
# Rank strategies using multi-criteria scoring (direct CSV input)
docker exec backtrader-engine python /app/scripts/strategy_ranker.py \
  --csv-input results/parallel_backtests.csv \
  --output rankings.csv \
  --top-n 15

# Analyze correlations (requires time series data)
docker exec backtrader-engine python /app/scripts/correlation_analyzer.py \
  --rankings rankings.csv \
  --output filtered_strategies.csv \
  --verbose

# Optimize portfolio allocation
docker exec backtrader-engine python /app/scripts/portfolio_optimizer.py \
  --strategies rankings.csv \
  --output portfolio_allocation.csv \
  --method equal_weight \
  --verbose

# Generate comprehensive portfolio analytics
docker exec backtrader-engine python /app/scripts/portfolio_analytics.py \
  --allocations portfolio_allocation.csv \
  --output portfolio_report.md \
  --export portfolio_analytics.json \
  --verbose
```

**Features**:
- **Multi-Criteria Ranking**: 5-factor scoring (Sharpe 40%, Consistency 20%, Drawdown 20%, Frequency 10%, Efficiency 10%)
- **Correlation Analysis**: Framework for identifying correlated strategies (time series data required for full implementation)
- **Portfolio Construction**: Equal weight, volatility-adjusted, and risk parity allocation methods
- **Capital Constraints**: $1000 maximum portfolio value, 3 position maximum
- **Performance Analytics**: Comprehensive portfolio metrics and risk decomposition
- **CLI Integration**: Full command-line interfaces for all components
- **Parallel Processing**: Handles 100+ strategies efficiently (<1 minute for 328 strategies)

**Ranking Criteria**:
- **Sharpe Ratio (40%)**: Risk-adjusted returns
- **Consistency (20%)**: Rolling 30-day return stability
- **Drawdown Control (20%)**: Maximum drawdown percentage
- **Trade Frequency (10%)**: Trades per month
- **Capital Efficiency (10%)**: Return per dollar deployed

**Portfolio Methods**:
- **Equal Weight**: Simple equal allocation to top strategies
- **Volatility-Adjusted**: Inverse volatility weighting
- **Risk Parity**: Equal risk contribution from each strategy

#### Walk-Forward Analysis with Parallel Backtesting (Epic 14)

**Status**: ‚úÖ Implemented - Rolling window out-of-sample validation with distributed parallel execution.

```bash
# Submit backtest with MLflow tracking via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" \
  -H "Content-Type: application/json" \
  -d '{
    "strategy": "sma_crossover",
    "symbols": ["SPY"],
    "parameters": {"fast_period": 10, "slow_period": 20},
    "start_date": "2020-01-01",
    "end_date": "2024-12-31",
    "mlflow_project": "Q1_2025",
    "mlflow_asset_class": "Equities",
    "mlflow_strategy_family": "MeanReversion"
  }'

# High-frequency backtest via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" \
  -H "Content-Type: application/json" \
  -d '{
    "strategy": "sma_crossover",
    "symbols": ["SPY"],
    "parameters": {"fast_period": 10, "slow_period": 20},
    "start_date": "2025-10-07",
    "end_date": "2025-10-14",
    "resolution": "1m",
    "mlflow_project": "HighFreq_2025",
    "mlflow_asset_class": "Equities",
    "mlflow_strategy_family": "MeanReversion"
  }'
  --mlflow \
  --project Q1_2025 \
  --asset-class Equities \
  --strategy-family HighFrequency
```

**Features**:
- **Rolling Windows**: Configurable in-sample/out-of-sample splits
- **Parallel Execution**: Each window processed via distributed backtesting
- **Overfitting Detection**: Performance degradation analysis
- **MLflow Integration**: Comprehensive experiment tracking
- **Stability Metrics**: Consistency analysis across time periods
- **Stationarity Tests**: Statistical validation of performance consistency

**Analysis Output**:
- Average out-of-sample Sharpe ratio
- Performance stability score
- Consistency ratio (positive Sharpe windows)
- Stationarity test results
- Window-by-window detailed results

#### Auto-Scaling Workers (Epic 20)

**Status**: ‚úÖ Implemented - Dynamic worker scaling based on queue length monitoring.

```bash
# Run auto-scaling manager in background
docker exec -d backtrader-engine python /app/scripts/auto_scaling_manager.py \
  --min-workers 1 \
  --max-workers 10 \
  --scale-up-threshold 5 \
  --scale-down-threshold 1 \
  --check-interval 30

# Run with custom settings
docker exec -d backtrader-engine python /app/scripts/auto_scaling_manager.py \
  --redis-host redis \
  --redis-port 6379 \
  --min-workers 2 \
  --max-workers 20 \
  --scale-up-threshold 10 \
  --scale-down-threshold 2
```

**Features**:
- **Queue Monitoring**: Continuous monitoring of Redis job queue length
- **Dynamic Scaling**: Automatic scale up/down based on workload
- **Docker Integration**: Manages worker containers via Docker Compose
- **Configurable Thresholds**: Customizable scale up/down triggers
- **Health Monitoring**: Worker health checks and automatic recovery

**Scaling Algorithm**:
- **Scale Up**: When queue length >= threshold, double current workers (up to max)
- **Scale Down**: When queue length <= threshold and workers > min, halve workers (down to min)
- **Stable**: Maintain current count when within optimal range

**Benefits**:
- **Cost Efficiency**: Only run workers when needed
- **Performance**: Scale up during high workload periods
- **Resource Management**: Prevent over-provisioning during low activity



#### Project Management (Epic 17)

**Status**: ‚úÖ Implemented - Intelligent experiment organization and querying.

```python
from scripts.project_manager import ProjectManager

pm = ProjectManager()

# Create organized experiments
exp_id = pm.create_experiment(
    project="Q1_2025",
    asset_class="Equities",
    strategy_family="MeanReversion",
    strategy="SMACrossover"
)

# Query experiments
equity_experiments = pm.query_by_asset_class("Equities")
research_projects = pm.query_by_status("research")

# Compare strategies
comparison = pm.compare_strategies("Q1_2025", "sharpe_ratio")
```

**Query Patterns**:
- `query_by_project("Q1_2025")` - All experiments in project
- `query_by_asset_class("Equities")` - All equity strategies
- `query_by_strategy_family("MeanReversion")` - All mean reversion strategies
- `query_recent_experiments(days=7)` - Recent experiments

# Deploy to live trading
./scripts/start_live_trading.sh
```

## Data Management

### Download Historical Data

**Data Download Process**: Let the developer know what data you need in what format and resolution, and they will download it for you using the data download scripts.

**Data Request Format**:
```
Developer Request:
Please download historical market data with the following specifications:
- Symbols: [list your required symbols]
- Date Range: [start date] to [end date]
- Resolution: Daily / 1m / 5m / 15m / 1h
- Data Type: Trade / Quote
- Format: CSV (Backtrader-compatible OHLCV format)
- Special Requirements: [any specific formatting needs]

Example for daily data:
- Symbols: SPY, AAPL, MSFT, GOOGL, AMZN
- Date Range: 2020-01-01 to 2024-12-31
- Resolution: Daily
- Data Type: Trade
- Format: CSV (Backtrader-compatible OHLCV format)

Example for high-frequency data:
- Symbols: SPY, QQQ, NVDA, TSLA
- Date Range: 2025-10-01 to 2025-11-30
- Resolution: 1m
- Data Type: Trade
- Format: CSV (Databento format with timestamp conversion)
```

The data download process:
- Requires IB credentials in `.env` file
- Connects to IB Gateway via ib_insync
- Downloads data directly from Interactive Brokers
- Supports multiple symbols (comma-separated)
- Data types: Trade, Quote
- Resolutions: Daily, Hour, Minute, Second
- Markets: USA (default)

### Symbol Discovery Engine (Epic 18)

**Status**: ‚úÖ Implemented - Autonomous symbol discovery using IB API scanner functionality.

Use [scripts/symbol_discovery.py](scripts/symbol_discovery.py) for autonomous symbol discovery:

```bash
# Basic usage - discover high volume stocks
source venv/bin/activate
python scripts/symbol_discovery.py --scanner high_volume --output csv

# Advanced usage with filters
python scripts/symbol_discovery.py \
  --scanner volatility_leaders \
  --min-volume 2000000 \
  --atr-threshold 1.5 \
  --min-price 10.0 \
  --max-price 200.0 \
  --output json

# Dry run to see configuration
python scripts/symbol_discovery.py --scanner top_gainers --dry-run

# View discovery statistics
python scripts/symbol_discovery.py --stats

# Skip database operations (file output only)
python scripts/symbol_discovery.py --scanner most_active_stocks --no-db --output csv
```

#### Scanner Types

- `high_volume`: High volume stocks ($2M+ avg daily volume)
- `top_gainers`: Top percentage gainers (daily)
- `top_losers`: Top percentage losers (daily)
- `most_active_stocks`: Most active stocks by volume
- `most_active_etfs`: Most active ETFs by volume
- `volatility_leaders`: Highest volatility (ATR-based)

#### Filter Options

- `--min-volume`: Minimum average daily volume
- `--atr-threshold`: Minimum ATR (volatility) threshold
- `--min-price`: Minimum stock price
- `--max-price`: Maximum stock price
- `--exchanges`: Allowed exchanges (NYSE,NASDAQ,ARCA)

#### Output Formats

- `--output csv`: Comma-separated values (default)
- `--output json`: JSON array format
- `--output both`: Generate both CSV and JSON

#### Features

- **IB Scanner API Integration**: Direct connection to Interactive Brokers scanner
- **Intelligent Filtering**: Liquidity, volatility, price range, exchange validation
- **ATR Calculation**: Real-time volatility analysis using historical data
- **PostgreSQL Storage**: Historical symbol tracking and performance data
- **CLI Flexibility**: Full parameter override capability
- **Comprehensive Logging**: Detailed execution logs and error handling

#### Output Files

Results saved to `data/discovered_symbols/` with timestamped filenames:
```
data/discovered_symbols/high_volume_20251105_174142.csv
data/discovered_symbols/high_volume_20251105_174142.json
```

CSV format includes: symbol, exchange, sector, avg_volume, atr, price, pct_change, market_cap, volume, discovery_timestamp

### Data Storage Structure

```
data/
‚îú‚îÄ‚îÄ raw/        # Downloaded market data
‚îú‚îÄ‚îÄ processed/  # Cleaned/transformed data
‚îú‚îÄ‚îÄ sqlite/     # Trade history database
‚îî‚îÄ‚îÄ discovered_symbols/  # Symbol discovery outputs (Epic 18)
```

## Database Optimization (Epic 17)

**Status**: ‚úÖ Implemented - PostgreSQL performance optimization and archival strategies.

### Performance Optimization

The platform includes automated database optimization scripts for MLflow PostgreSQL backend:

```bash
source venv/bin/activate
python scripts/db_optimizer.py
```

This generates:
- `scripts/db_optimization/performance_indexes.sql` - Index optimization
- `scripts/db_optimization/archive_data_90days.sql` - Data archival
- `scripts/db_optimization/cleanup_maintenance.sql` - Maintenance scripts
- `scripts/db_optimization/performance_monitoring.sql` - Monitoring queries
- `scripts/db_optimization/scaling_guide.md` - Scaling documentation

### Key Optimizations

- **Composite Indexes**: Optimized for common query patterns
- **Partial Indexes**: Efficient queries on recent data
- **Archival Strategy**: Automatic archiving of experiments >90 days old
- **Maintenance Scripts**: Automated cleanup and reindexing
- **Performance Monitoring**: Query performance tracking

### Scaling Guide

See `scripts/db_optimization/scaling_guide.md` for:
- Vertical scaling recommendations
- Connection pooling setup
- Backup strategies
- Troubleshooting common issues

## Live Trading

### Start Live Trading

```bash
source venv/bin/activate
./scripts/start_live_trading.sh
```

The script will:
- Validate IB credentials in `.env`
- Check strategy exists
- Deploy to Backtrader with IB integration
- Run in detached mode (or foreground based on config)

### Stop Live Trading

```bash
./scripts/stop_live_trading.sh
```

### Emergency Stop

If you need to immediately liquidate all positions and stop trading:

```bash
./scripts/emergency_stop.sh
```

This will:
- Query database for open positions
- Liquidate each position via Backtrader
- Stop the algorithm
- Log emergency event

### Backtrader Strategy Structure

Live trading strategies live in [strategies/](strategies/):
- `base_strategy.py` - Base strategy template with risk management
- `risk_manager.py` - Risk management library (position/loss/concentration limits)
- `db_logger.py` - Database logging for monitoring
- `sma_crossover.py` - Example strategy
- `sma_crossover_risk_managed.py` - Example with full risk management

Strategies use Backtrader's native features:
- `self.broker` for position tracking and cash management
- `self.buy()` / `self.sell()` / `self.close()` for orders
- `bt.Strategy` base class with `__init__()` and `next()` methods
- Risk checks via `BaseStrategy` inheritance

## Backtesting

### Run Backtest

Use FastAPI backend for programmatic execution:

```bash
# Submit backtest job via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" \
  -H "Content-Type: application/json" \
  -d '{
    "strategy": "sma_crossover",
    "symbols": ["SPY"],
    "parameters": {"fast_period": 10, "slow_period": 20},
    "start_date": "2020-01-01",
    "end_date": "2024-12-31",
    "initial_cash": 100000
  }'
```

Results saved to `results/backtests/{uuid}.json` with:
- Backtest ID (UUID)
- Strategy path
- Time period
- Commission model used
- Full performance metrics (Sharpe, drawdown, returns, etc.)
- Completion status

### Commission Models

Configured in [config/cost_config.yaml](config/cost_config.yaml):

**ib_standard** (default):
- Commission: $0.005/share, $1.00 minimum
- SEC fees: $27.80 per $1M (sells only)
- Slippage: 5 bps market orders, 0 bps limit orders
- Spread: 2 bps typical

**ib_pro** (tiered pricing):
- Commission: $0.0035/share, $0.35 minimum
- Same fees/slippage as standard

### Backtest Configuration

[config/backtest_config.yaml](config/backtest_config.yaml):
- Initial capital: $100,000
- Default resolution: Daily
- Benchmark: SPY
- Parallel execution: enabled (8 workers)
- Results caching: enabled

## Monitoring Dashboard

Streamlit dashboard runs on port 8501 with 9 tabs for comprehensive monitoring:

```bash
# Access at http://localhost:8501
```

### Dashboard Tabs

1. **üìä Dashboard**: Account summary, risk metrics, equity curve
2. **üíº Live Trading**: Active positions with P&L tracking
3. **üìú Trade Log**: Complete trade history with execution details
4. **üìà Performance**: Performance analytics and metrics
5. **üî¨ Backtests**: Historical backtest results (JSON-based)
6. **‚öôÔ∏è Optimization**: Parameter optimization history (JSON-based)
7. **üß™ MLflow**: Experiment tracking and comparison (Epic 17)
8. **üè• Health**: System health monitoring and diagnostics (${FASTAPI_BACKEND_URL:-http://localhost:8230})
9. **‚öôÔ∏è Settings**: Environment variables and configuration (${FASTAPI_BACKEND_URL:-http://localhost:8230})

### MLflow Integration (Epic 17)

The **üß™ MLflow** tab provides AI Research Lab features:

**Features**:
- **Real-time Metrics**: Total experiments, runs, recent activity, failed runs
- **Project Browser**: Filter experiments by project, asset class, strategy family
- **Experiment Listing**: View all experiments with best Sharpe, returns, drawdown
- **Experiment Comparison**: Select 2-5 experiments for side-by-side comparison
- **Performance Charts**:
  - Sharpe Ratio comparison (bar chart)
  - Total Returns comparison (bar chart)
  - Risk-Adjusted Returns scatter plot
- **Link to MLflow UI**: Direct link to full MLflow UI (http://localhost:5000)

**Usage**:
1. Start platform: `./scripts/start.sh`
2. Run backtests with MLflow: `--mlflow` flag
3. Access dashboard: http://localhost:8501
4. Navigate to MLflow tab
5. Use filters and comparison tools

**Note**: MLflow tab requires MLflow server running. If unavailable, dashboard shows warning with startup instructions.

### Data Access

Dashboard has read-only access to:
- `data/` - Historical data
- `results/` - Backtest outputs (JSON files)
- `logs/` - Application logs
- **MLflow Server**: Experiment tracking via http://mlflow:5000

## Configuration Files

Critical config files in [config/](config/):
- `backtest_config.yaml` - Backtest runner settings
- `cost_config.yaml` - IB commission/slippage models
- `data_config.yaml` - Data download settings
- `optimization_config.yaml` - Parameter optimization (Epic 14)
- `walkforward_config.yaml` - Walk-forward analysis (Epic 14)

## Project Rules

**Environment**: Always use `source venv/bin/activate` before Python commands

**Docker Logs**: NEVER use `-f` flag with `docker compose logs` or `docker logs`

**Git**: `.env` file is gitignored - never commit credentials

**Trading Mode**: Default is `paper` - thoroughly test before switching to `live`

**Results**: All backtest results auto-saved to `results/backtests/` with UUID

## Current Implementation Status

**Completed Epics**:
- ‚úÖ **Epic 11**: Migration Foundation (100%)
  - Docker architecture migrated to Backtrader
  - IB connection framework via ib_insync
  - Data pipeline operational
  - Project structure established

- ‚úÖ **Epic 18**: Symbol Discovery Engine (100%)
  - IB Scanner API integration
  - 6 scanner types (high_volume, top_gainers, volatility_leaders, etc.)
  - Intelligent filtering (liquidity, volatility, price range, exchange)
  - PostgreSQL database storage for historical tracking
  - CLI interface with filter overrides
  - CSV/JSON output formats

- ‚úÖ **Epic 21**: Strategy Ranking & Portfolio Optimizer (100%)
  - Multi-criteria strategy ranking system (Sharpe, consistency, drawdown, frequency, efficiency)
  - Correlation analysis framework (requires time series data for full implementation)
  - Portfolio allocation engine (equal weight, volatility-adjusted, risk parity methods)
  - Capital and position limit constraints ($1000 max, 3 positions max)
  - Comprehensive portfolio analytics and reporting
  - CLI interfaces for all components
  - Integration with parallel backtest pipeline
  - Processed 328 strategies in <1 minute (exceeds 100+ strategy requirement)

- ‚úÖ **Epic 26**: Quant Director API Integration (100%)
  - Symbol Discovery API with background processing and Redis queue
  - Strategy Ranking API with multi-criteria analysis and job tracking
  - Docker containerization with dedicated discovery-worker and ranking-worker services
  - PostgreSQL database integration for results persistence
  - Complete API documentation and OpenAPI specifications
  - End-to-end workflow testing and validation

**Partially Completed Epics**:
- üîÑ **Epic 12**: Core Backtesting Engine (87.5%)
  - ‚úÖ Cerebro engine configuration
  - ‚úÖ Analyzers and performance metrics
  - ‚úÖ Commission models (IB Standard, IB Pro)
  - ‚úÖ Backtest execution script
  - ‚úÖ Result parser
  - ‚è≥ US-12.6: Monitoring dashboard integration (pending)

- üîÑ **Epic 13**: Algorithm Migration & Risk (37.5%)
  - ‚úÖ Base strategy template
  - ‚úÖ Risk management framework
  - ‚úÖ Example risk-managed strategy
  - ‚è≥ Additional strategy migrations (pending)
  - ‚è≥ Live trading deployment (pending)
  - ‚è≥ Database logger integration (pending)
  - ‚è≥ Strategy testing (pending)

**Pending Epics**:
- üìã **Epic 14**: Advanced Features (0%)
  - Parameter optimization
  - Walk-forward analysis
  - Live trading enhancements
  - Claude Skills completion

- üìã **Epic 15**: Testing & Validation (0%)
  - Unit tests
  - Integration tests
  - Paper trading validation
  - Performance validation

- üîÑ **Epic 16**: Documentation & Cleanup (In Progress)
  - Documentation updates
  - LEAN dependency removal
  - Code cleanup
  - Production cutover

See [stories/epic-12-stories.md](stories/epic-12-stories.md), [stories/epic-13-stories.md](stories/epic-13-stories.md), etc. for details.

## Architecture Notes

### Service Dependencies

```
monitoring ‚Üí sqlite
backtrader ‚Üí ib-gateway, sqlite
```

All services restart automatically (`restart: unless-stopped`) unless explicitly stopped.

### Volume Mounts

- `backtrader` service mounts: strategies/, scripts/, config/, data/, results/, logs/
- `monitoring` service has read-only access to data/, results/, logs/
- `sqlite` service mounts data/sqlite/ for persistence

### IB Gateway Health Checks

Health check runs every 30s via `nc -z localhost 4001`:
- Timeout: 10s
- Retries: 3
- Tests API port availability (not authentication)

## Claude Skills

Three specialized skills available for automation:

**data-manager**: Download and validate market data from IB via ib_insync
**backtest-runner**: Execute backtests with performance analysis
**parameter-optimizer**: Optimize strategy parameters (Epic 14)

These auto-invoke when Claude detects related natural language requests.

## AI Code Delegation (Gemini Integration)

For large-scale implementation tasks, Claude Code can delegate work to Gemini AI to leverage its long context window and code generation capabilities while maintaining project context and coding standards.

### When to Use Gemini Delegation

**Ideal Use Cases**:
- **Multi-File Implementations**: Implementing features across 5+ files simultaneously
- **Large-Scale Refactoring**: Applying consistent changes across entire directories (e.g., converting callback patterns to async/await)
- **Comprehensive Testing**: Writing unit tests for multiple modules at once
- **New Module Development**: Implementing complete modules from specifications

**Examples**:
```bash
# Multi-file feature implementation
"Implement authentication system across user service, auth middleware, and token validation modules"

# Large-scale refactoring
"Refactor entire data pipeline in strategies/ to use async/await patterns consistently"

# Comprehensive testing
"Write comprehensive unit tests for strategies/base_strategy.py and strategies/risk_manager.py"

# Module from spec
"Implement risk_calculator.py based on specifications in docs/risk_spec.md"
```

### How It Works

1. **Automatic Detection**: Claude Code detects when a task is better suited for Gemini (large scope, multi-file changes)
2. **Context Preservation**: Project context, coding standards, and architectural patterns are passed to Gemini
3. **Constrained Execution**: File boundaries and modification scope are strictly controlled
4. **Quality Assurance**: Generated code is validated against project standards

### Benefits

- **Long Context Window**: Handle larger codebases and more complex changes in a single pass
- **Parallel Processing**: Multi-file implementations without sequential bottlenecks
- **Consistency**: Apply patterns consistently across multiple files
- **Efficiency**: Faster turnaround for large-scale coding tasks

### Manual Invocation

While Claude Code automatically delegates when appropriate, you can explicitly request Gemini delegation:

```bash
# Explicit delegation request
"Use Gemini to implement the entire risk management module across these 8 files"
```

**Important Notes**:
- Gemini delegation is most effective for implementation tasks. For analysis, architecture design, or debugging, Claude Code's native capabilities are typically better suited.
- **Always use maximum bash timeout** (600000ms / 10 minutes) when delegating to Gemini, as large-scale code generation can take significant time to complete.

## Strategy Development Guide

### Creating a New Strategy

1. **Inherit from BaseStrategy** (recommended for risk management):
   ```python
   from strategies.base_strategy import BaseStrategy
   import backtrader as bt

   class MyStrategy(BaseStrategy):
       params = (
           ('param1', 20),
       )

       def __init__(self):
           # Initialize indicators
           self.sma = bt.indicators.SMA(self.data.close, period=self.params.param1)

       def next(self):
           # Strategy logic
           if not self.position:
               if self.data.close[0] > self.sma[0]:
                   self.buy()
           else:
               if self.data.close[0] < self.sma[0]:
                   self.sell()
   ```

2. **Test via backtest**:
   ```bash
   curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" \
     -H "Content-Type: application/json" \
     -d '{
       "strategy": "my_strategy",
       "symbols": ["SPY"],
       "parameters": {},
       "start_date": "2020-01-01",
       "end_date": "2024-12-31"
     }'
   ```

3. **Deploy to live trading**:
   ```bash
   ./scripts/start_live_trading.sh
   ```

### Risk Management Integration

All strategies should inherit from [strategies/base_strategy.py](strategies/base_strategy.py:1) for automatic risk management:

- **Position Limits**: `max_position_size` parameter
- **Loss Limits**: `max_daily_loss`, `max_drawdown` parameters
- **Concentration Limits**: `max_concentration` parameter
- **Automatic Checks**: Pre-order risk validation
- **Database Logging**: Automatic trade/position logging

See [strategies/risk_manager.py](strategies/risk_manager.py:1) for full framework details.

## Migration from LEAN

This platform was migrated from QuantConnect LEAN to Backtrader in November 2025. Key changes:

**Framework Changes**:
- LEAN QCAlgorithm ‚Üí Backtrader bt.Strategy
- LEAN CLI ‚Üí Python scripts + ib_insync
- LEAN data ‚Üí Direct IB data via ib_insync
- LEAN live trading ‚Üí Backtrader live trading with IB broker

**Command Changes**:
- `lean backtest` ‚Üí `python scripts/run_backtest.py`
- `lean live deploy` ‚Üí `./scripts/start_live_trading.sh`
- `lean data download` ‚Üí Request developer to download data (specify requirements)

**Benefits**:
- ‚úÖ Zero vendor lock-in (100% open-source)
- ‚úÖ Full control over execution and data
- ‚úÖ More flexible strategy development
- ‚úÖ Better integration with Python ecosystem
- ‚úÖ Lower costs (no QuantConnect subscription)

See [MIGRATION_SUMMARY.md](MIGRATION_SUMMARY.md) for complete migration details and [docs/MIGRATION_GUIDE.md](docs/MIGRATION_GUIDE.md) for LEAN‚ÜíBacktrader conceptual mapping.

## Troubleshooting

### Common Issues

**"ModuleNotFoundError: No module named 'backtrader'"**
- Activate virtual environment: `source venv/bin/activate`
- Reinstall: `pip install backtrader`

**"Connection refused to IB Gateway"**
- Check IB Gateway is running: `docker compose ps ib-gateway`
- Check credentials in `.env` file
- Verify port 4001 (paper) or 4002 (live) is accessible
- Test connection: `python scripts/ib_connection.py`

**"No data returned for symbol SPY"**
- Verify IB Gateway connection
- Check symbol is valid and market is open
- Verify date range is valid (not future dates)
- Check IB account has market data subscriptions

**"Backtest script fails with import error"**
- Ensure strategy file exists in `strategies/` directory
- Check strategy class name matches import path
- Verify all required indicators are imported

### Debug Mode

Enable debug logging in scripts:
```bash
# Set environment variable
export DEBUG=1

# Run with verbose output via API
curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" \
  -H "Content-Type: application/json" \
  -d '{
    "strategy": "my_strategy",
    "symbols": ["SPY"],
    "parameters": {},
    "start_date": "2020-01-01",
    "end_date": "2024-12-31",
    "verbose": true
  }'
```

## Performance Best Practices

1. **Use Daily Data**: Start with daily resolution, optimize to intraday only if needed
2. **Limit Symbols**: Start with 1-5 symbols, expand gradually
3. **Cache Results**: Backtest results are cached, reuse when possible
4. **Parallel Execution**: Use `--parallel` flag for multi-symbol backtests (Epic 14)
5. **Monitor Memory**: Large datasets can consume significant memory

## Security Considerations

- **Never commit credentials**: `.env` is gitignored, keep it that way
- **Use paper trading first**: Validate all strategies in paper mode
- **Review risk limits**: Set appropriate position/loss limits
- **Monitor logs**: Regularly check logs for unusual activity
- **Secure VNC**: Change default VNC password in production

---

**Quick Reference Card**:
- Start services: `./scripts/start.sh`
- Download data: Request developer to download data (specify symbols, dates, resolution, format)
- QC cloud backtest: `python scripts/qc_cloud_backtest.py --open`
- QC strategy file: `lean_projects/RSIMeanReversion/main.py`
- Symbol discovery (API): `curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/discovery/scan" -H "Content-Type: application/json" -d '{"scanner_name": "high_volume", "parameters": {"number_of_rows": 50}}'`
- Strategy ranking (API): `curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/ranking/analyze" -H "Content-Type: application/json" -d '{"input_type": "results_dir", "input_source": "results/backtests"}'`
- Run backtest (Backtrader): `curl -X POST "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/backtests/run" -H "Content-Type: application/json" -d '{"strategy": "sma_crossover", "symbols": ["SPY"], "start_date": "2020-01-01", "end_date": "2024-12-31"}'`
- Portfolio analytics: `curl "${FASTAPI_BACKEND_URL:-http://localhost:8230}/api/analytics/portfolio" | jq '.strategy_rankings'`
- Live trading: `./scripts/start_live_trading.sh`
- Emergency stop: `./scripts/emergency_stop.sh`
- View dashboard: `http://localhost:8501`
